{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')\n",
    "import src.data.data_loader as dl\n",
    "from src.features.vectorizer import Vectorizer\n",
    "from src.models.topic_models import TopicModel\n",
    "import pandas as pd\n",
    "import sklearn.utils as skutil\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data \n",
    "language = 'german'\n",
    "typex = 'forum'\n",
    "# Vectorization\n",
    "min_df = 0.005\n",
    "max_df = 0.9\n",
    "\n",
    "# Topic Modeling\n",
    "algorithm = 'nmf'\n",
    "num_topics = 170"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['servicelink erscheinen bios buchen daniel suarez tipp buch hausen -pron- /r/buecher kreiiiisch ohnmacht fallen runterwähl freu danken einstieg empfehlen dito genau solch kommentar /r/de drecksmemes versuchen meme extra subreddit don\\'t panic daniel surez fan board daemon kill decision\"](http://stilstand.de/wo-lebt-der-2/#comment-2879 fallen kennen daemon dark net lesung hörspiel edit datum kommentare stilstand paar wochen bevor namen snowden](http://stilstand.de/wo-lebt-der-2/#comment-2898 kennen edit typo eher maimais konsequente abschieben maimais ursprungsunterlases abschieben notfalls kreiswichs freuen sowas echt gefühl ner listen stehen daemon darknet kaufen', 'bio teuer bio gutbio preisen deleted bio abfall kaufen bio zeugs kosten doppeln normalprodukt meistens gutshof klingen nem ziemlich schnäppchen bewertung fragende aha tierprodukten ausgehen tier medikament vollgepumpt pflanzlich bio-produkte pestizid ähnlich bespritzen', 'rufen bio-linseneintopf trotz intensiv qualitätskontrollen leider ausschließen linse dose befinden klaren zeugen vegan linseneintopf passieren kaufe getrocknet linse warte linseneintopf grad würstchen speck plastikteilchen reinmache vegan plastikteile tierleichen glassplitter](http://www.express.de/rueckruf-aktion-glassplitter-in-linseneintopf-22088432 plastikteilchen vegan thats the joke allgemein sprechen erdöl dinosaurier baum dinosaurier zumindest homöopathisch vegan plastik erdöl verflüssigen dinosaurier homöopathisch nice wissenschaft obsiegt', 'bio-pionier rapunzel sichern niemals aldi lidl rapunzel geilen nuss-nougatcreme schweineteuer rapunzel halt leisten persönlich vertrauen demeter rapunzel fraß gehoben pöbeln hauptsache bio samba heißen zeugen süchtig haselnussgehalt probier unbedingt cocoscreme naturland demeter fraß gepöbelt hobeln probieren nutella einpacken passieren kokos nix anfangen pur haselnusscreme hammer teuer verwenden buttercreme nen kuchen heilig scheißen geil werd testen haselnusscreme frühstücksbrötchen rapshonig nutella welt buttercreme-rezept <URL> einfach rezeptmenge lockern haselnuss glasen setzen schicht haselnussöl unterrühren buttercreme gießen lieb butter-menge reduzieren scheiße klingen geil teig empfehlen nen bisquit geröstete haselnuß zimt kakao option kakao sprechen eher werd probieren', 'lebensmittelchemiker finden pestizid angeblich bio-superfoods glauben schnittmenge leute bio-superfoods kaufen bericht anschauen ungefähr null moringa ware quinoa chia langweilig wasser lawi global normal gemüse papier krasse wassermengen verbrauchen fleisch tomate niederlande spanien apfel brauchen niedrig rindfleisch entscheidender regen bewässerung oberflächenwasser grundwasser handeln effizient wässern mexiko anbauort zum teil wasserreserven genau hingucken avocado kauf beid gruppe verschwinden klein gruppe überschrift lesen gewinnen generell grundüberlegenheitsgefühl körnerfresser quinoa neu canihua aktuell hype rezept nochmal wiederholen canihua eigentlich trendfood aztekengottheit anhören liegt tonne essen brauchen amaranth rot quinoa chiasamen aktuell glutenfreies brot igitt glutenfreies müsli lecker bio lactosefreie milchprodukte angebot naja ginseng anscheinen trennung superfoods normal futtern folgen vornehm europa/n.amerika üblich ungesund fraß asiatischer/afrikanischer/s.amerikanischer herkunft superfood völlig lächerlich jed exotische superfood einheimisch fütterchen welch ähnlich lässt vermarkten stelle anstatt chia versuchen leinsamen hypen']\n"
     ]
    }
   ],
   "source": [
    "data = dl.get_forum_threads_by_language(language, typex)\n",
    "texts = data['thread_texts']\n",
    "\n",
    "def min_length (texts,min_characters):\n",
    "    neu = []\n",
    "    for t in texts: \n",
    "        token_perdoc_list = t.split()\n",
    "        token_min_character = []\n",
    "        for token in token_perdoc_list: \n",
    "            if len(token)>= min_characters: \n",
    "                token_min_character.append(token)\n",
    "        joined = (\" \").join(token_min_character)\n",
    "        neu.append(joined)\n",
    "    return neu\n",
    "\n",
    "texts = min_length(texts,3)\n",
    "print(texts[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = Vectorizer('tfidf', texts, min_df=min_df, max_df=max_df)\n",
    "vec.save('tagged/vectorizer/{}_{}_{}_pos.pkl'.format(algorithm, language, typex,\"tagged\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_term_matrix = vec.get_document_token_matrix(texts)\n",
    "id2token = vec.get_id2token_mapping()\n",
    "document_term_matrix = skutil.shuffle(document_term_matrix, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 reached after 1.027 seconds, error: 19.198221\n",
      "Epoch 20 reached after 1.886 seconds, error: 18.759338\n",
      "Epoch 30 reached after 2.724 seconds, error: 18.622696\n",
      "Epoch 40 reached after 3.575 seconds, error: 18.559748\n",
      "Epoch 50 reached after 4.423 seconds, error: 18.522582\n",
      "Epoch 60 reached after 5.272 seconds, error: 18.497195\n",
      "Epoch 70 reached after 6.142 seconds, error: 18.480217\n",
      "Epoch 80 reached after 7.076 seconds, error: 18.468323\n",
      "Epoch 90 reached after 8.025 seconds, error: 18.457508\n",
      "Epoch 100 reached after 9.109 seconds, error: 18.448400\n",
      "Epoch 110 reached after 10.206 seconds, error: 18.441341\n",
      "Epoch 120 reached after 11.345 seconds, error: 18.434714\n",
      "Epoch 130 reached after 12.507 seconds, error: 18.428932\n",
      "Epoch 140 reached after 13.676 seconds, error: 18.423328\n",
      "Epoch 150 reached after 14.894 seconds, error: 18.417920\n",
      "Epoch 160 reached after 16.213 seconds, error: 18.413962\n",
      "Epoch 170 reached after 17.428 seconds, error: 18.410897\n",
      "Epoch 180 reached after 18.586 seconds, error: 18.408125\n",
      "Epoch 190 reached after 19.796 seconds, error: 18.405676\n",
      "Epoch 200 reached after 21.020 seconds, error: 18.403629\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Maria\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\nmf.py:1035: ConvergenceWarning: Maximum number of iteration 200 reached. Increase it to improve convergence.\n",
      "  \" improve convergence.\" % max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "model = TopicModel('nmf', num_topics, document_term_matrix, id2token)\n",
    "model.save('tagged/topic_models/nmf/{}_{}_{}_{}_articles_{}.pkl'.format(algorithm, language, typex,\"tagged\",num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
